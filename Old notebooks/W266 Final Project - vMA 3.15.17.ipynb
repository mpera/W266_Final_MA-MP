{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## W266 Final Project\n",
    "\n",
    "### Classifying the Political Ideology of News Articles\n",
    "\n",
    "#### Matt Acconciamessa and Megan Pera\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load and save data into liberal, conservative and neutral objects\n",
    "[lib, con, neutral] = pickle.load(open('ibcData.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liberal examples (out of  2025  sentences): \n",
      "Forcing middle-class workers to bear a greater share of the cost of government weakens their support for needed investments and stirs resentment toward those who depend on public services the most .\n",
      "Because it would not be worthwhile to bring a case for $ 30.22 , the arbitration clause would , as a practical matter , deny the Concepcions any relief and , more important , eliminate a class action that might punish AT&T for its pattern of fraudulent behavior .\n",
      "Indeed , Lind argues that high profits and high wages reinforce each other because workers then have the wherewithal to buy the products they are making .\n",
      "In fairness , it should be noted that he devotes an entire chapter to New York Times political columnist Maureen Dowd , a liberal who makes much of the outsized rivalries , jealousies , and personalities that dominate American politics .\n",
      "Psychological tactics are social control techniques that operate at the level of the mind , with the goal of creating fear and making it difficult for protesters to successfully mobilize .\n"
     ]
    }
   ],
   "source": [
    "# **Code from Iyyer**\n",
    "\n",
    "# how to access sentence text\n",
    "print ('Liberal examples (out of ', len(lib), ' sentences): ')\n",
    "for tree in lib[0:5]:\n",
    "    print(tree.get_words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Conservative examples (out of  1701  sentences): \n",
      "Gore is getting rich from environmentalism , not just by being paid a whopping $ 175,000 per speech but by using political pressure to force government policy in a direction that benefits his business interests .\n",
      "The Federal Housing Finance Regulatory Reform Act of 2008 should have been an easy sell , since it purportedly aimed to assist homeowners , a more popular ( or at least more sentimentalized ) subset of Americans than greedy Wall Street tycoons .\n",
      "Yet for all its submerged class snobbery and anti-intellectualism disguised as cool detachment , the ultimate failure of the Washington media lies less with the personal failings of its elite members than its structural inadequacy .\n",
      "Rumsfeld then went on to discuss how China 's lack of transparency with respect to its defense expenditures and activities raises doubts in the region about China 's intentions .\n",
      "You never hear from the co-conspirators of the left-wing media how many innocent victims are dead , raped , and mutilated as a direct result of these left-wing policies and insane anti-gun laws .\n"
     ]
    }
   ],
   "source": [
    "print ('\\nConservative examples (out of ', len(con), ' sentences): ')\n",
    "for tree in con[0:5]:\n",
    "    print (tree.get_words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Neutral examples (out of  600  sentences): \n",
      "In this country , the beneficiaries of Apple 's success are , first , the designers , who have done wonders working with Steve Jobs to produce products that are beautiful and effective .\n",
      "The problem with this argument is that China reports about 68 percent of the world 's aquaculture production , and the FAO , which has been burned by inflated Chinese statistics before , expresses doubt about its stated production and growth rates . ''\n",
      "The soil exhaustion caused by the plantation system , as well as the relatively low productivity of forced labor , compelled planters to seek new lands to exploit .\n",
      "The same complexity that leads to such malfunctions also creates vulnerabilities that human agents can use to make computer systems operate in unintended ways .\n",
      "Threads of new awkwardness stretch out between them , and nature itself winks behind their backs and plays nasty tricks on them , scattering yellow clods of asters and groundsel , blanketing purple clover and pink flax , erecting stalks of huge -- but smelly -- purple arum flowers , sprinkling red buttercups , and hanging baby oranges and lemons on the trees around them .\n"
     ]
    }
   ],
   "source": [
    "print ('\\nNeutral examples (out of ', len(neutral), ' sentences): ')\n",
    "for tree in neutral[0:5]:\n",
    "    print (tree.get_words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Phrase labels for one tree: \n",
      "Liberal :  Forcing middle-class workers to bear a greater share of the cost of government weakens their support for needed investments and stirs resentment toward those who depend on public services the most .\n",
      "Liberal :  weakens their support for needed investments and stirs resentment toward those who depend on public services the most\n",
      "Liberal :  stirs resentment toward those who depend on public services the most\n"
     ]
    }
   ],
   "source": [
    "# how to access phrase labels for a particular tree\n",
    "ex_tree = lib[0]\n",
    "\n",
    "print ('\\nPhrase labels for one tree: ')\n",
    "\n",
    "# see treeUtil.py for the tree class definition\n",
    "for node in ex_tree:\n",
    "\n",
    "    # remember, only certain nodes have labels (see paper for details)\n",
    "    if hasattr(node, 'label'):\n",
    "        print (node.label, ': ', node.get_words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2025,)\n",
      "(1701,)\n",
      "(600,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "liberal = np.array(lib)\n",
    "conserv = np.array(con)\n",
    "neut = np.array(neutral)\n",
    "\n",
    "print (liberal.shape)\n",
    "print (conserv.shape)\n",
    "print (neut.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lib_labs = []\n",
    "lib_data = []\n",
    "for i in range(len(liberal)):\n",
    "    for node in liberal[i]:\n",
    "        if hasattr(node, 'label'):\n",
    "            lib_data.append(node.get_words())\n",
    "            lib_labs.append(node.label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10920\n",
      "10920\n"
     ]
    }
   ],
   "source": [
    "print (len(lib_data))\n",
    "print (len(lib_labs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weakens their support for needed investments and stirs resentment toward those who depend on public services the most\n"
     ]
    }
   ],
   "source": [
    "print(lib_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10920,)\n",
      "(10920,)\n",
      "['Liberal' 'Liberal' 'Liberal' 'Liberal' 'Liberal' 'Liberal' 'Liberal'\n",
      " 'Liberal' 'Liberal' 'Liberal' 'Neutral' 'Neutral' 'Liberal' 'Liberal'\n",
      " 'Liberal' 'Neutral' 'Neutral' 'Neutral' 'Neutral' 'Neutral' 'Liberal'\n",
      " 'Conservative' 'Conservative' 'Conservative' 'Conservative']\n"
     ]
    }
   ],
   "source": [
    "lib_data = np.array(lib_data)\n",
    "lib_labs = np.array(lib_labs)\n",
    "print (lib_data.shape)\n",
    "print (lib_labs.shape)\n",
    "print (lib_labs[0:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8192,)\n",
      "(8192,)\n"
     ]
    }
   ],
   "source": [
    "con_labs = []\n",
    "con_data = []\n",
    "for i in range(len(conserv)):\n",
    "    for node in conserv[i]:\n",
    "        if hasattr(node, 'label'):\n",
    "            con_data.append(node.get_words())\n",
    "            con_labs.append(node.label)\n",
    "\n",
    "con_data = np.array(con_data)\n",
    "con_labs = np.array(con_labs)\n",
    "print (con_data.shape)\n",
    "print (con_labs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Conservative' 'Conservative' 'Conservative' 'Conservative' 'Neutral'\n",
      " 'Neutral' 'Neutral' 'Conservative' 'Liberal' 'Liberal']\n"
     ]
    }
   ],
   "source": [
    "print(con_labs[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3509,)\n",
      "(3509,)\n"
     ]
    }
   ],
   "source": [
    "neut_labs = []\n",
    "neut_data = []\n",
    "for i in range(len(neut)):\n",
    "    for node in neut[i]:\n",
    "        if hasattr(node, 'label'):\n",
    "            neut_data.append(node.get_words())\n",
    "            neut_labs.append(node.label)\n",
    "\n",
    "neut_data = np.array(neut_data)\n",
    "neut_labs = np.array(neut_labs)\n",
    "print (neut_data.shape)\n",
    "print (neut_labs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22621,)\n",
      "(22621,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_all = np.concatenate((neut_data, lib_data, con_data), axis=0)\n",
    "labs_all = np.concatenate((neut_labs, lib_labs, con_labs), axis=0)\n",
    "\n",
    "print (data_all.shape)\n",
    "print (labs_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22621,)\n",
      "(22621,)\n",
      "['Conservative' 'Liberal' 'Liberal' 'Liberal' 'Neutral' 'Neutral'\n",
      " 'Conservative' 'Neutral' 'Neutral' 'Conservative']\n"
     ]
    }
   ],
   "source": [
    "def shuffle_in_unison(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    shuffled_a = np.empty(a.shape, dtype=a.dtype)\n",
    "    shuffled_b = np.empty(b.shape, dtype=b.dtype)\n",
    "    permutation = np.random.permutation(len(a))\n",
    "    for old_index, new_index in enumerate(permutation):\n",
    "        shuffled_a[new_index] = a[old_index]\n",
    "        shuffled_b[new_index] = b[old_index]\n",
    "    return shuffled_a, shuffled_b\n",
    "\n",
    "data_all, labs_all = shuffle_in_unison(data_all, labs_all)\n",
    "\n",
    "print (data_all.shape)\n",
    "print (labs_all.shape)\n",
    "print (labs_all[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18096\n",
      "(4525,)\n",
      "(18096,)\n"
     ]
    }
   ],
   "source": [
    "slice = int(.8*labs_all.shape[0])\n",
    "print(slice)\n",
    "data_train = data_all[:slice]\n",
    "labs_train = labs_all[:slice]\n",
    "data_test = data_all[slice:]\n",
    "labs_test = labs_all[slice:]\n",
    "\n",
    "print(labs_test.shape)\n",
    "print(labs_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "from sklearn.feature_extraction.text import *\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18096, 14115)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_counts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Multinomial Naive Bayes:\n",
      "alpha: 0.0001 F1: 0.729240341063\n",
      "alpha: 0.01 F1: 0.728915333866\n",
      "alpha: 0.05 F1: 0.727027508143\n",
      "alpha: 0.1 F1: 0.726426400602\n",
      "alpha: 0.2 F1: 0.724607676478\n",
      "alpha: 1.0 F1: 0.707094043106\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn import metrics\n",
    "        \n",
    "vect = CountVectorizer()\n",
    "train_vocab = vect.fit_transform(data_train)\n",
    "vocab = vect.get_feature_names()\n",
    "tvec = CountVectorizer(vocabulary=vocab)\n",
    "test_vocab = tvec.fit_transform(data_test)\n",
    "\n",
    "print(\"\")\n",
    "print(\"Multinomial Naive Bayes:\")\n",
    "for a in [0.0001, 0.01, .05, 0.1, 0.2, 1.0]:\n",
    "    mnb = MultinomialNB(alpha=a)\n",
    "    mnb.fit(train_vocab, labs_train)\n",
    "    mnbpreds = mnb.predict(test_vocab)\n",
    "    print(\"alpha:\", a, \"F1:\", metrics.f1_score(labs_test,mnbpreds,average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
